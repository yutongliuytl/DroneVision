{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import cv2\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras import models, layers, optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = {'L_': 'L',\n",
    "           'fi': 'Fist',\n",
    "           'pe': 'Peace',\n",
    "           'pa': 'Palm'\n",
    "            }\n",
    "\n",
    "gestures_map = {'Palm' : 0,\n",
    "                'L': 1,\n",
    "                'Fist': 2,\n",
    "                'Peace': 3\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((224, 224))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "def process_data(X_data, y_data):\n",
    "    X_data = np.array(X_data, dtype = 'float32')\n",
    "    if rgb:\n",
    "        pass\n",
    "    else:\n",
    "        X_data = np.stack((X_data,)*3, axis=-1)\n",
    "    X_data /= 255\n",
    "    y_data = np.array(y_data)\n",
    "    y_data = to_categorical(y_data)\n",
    "    return X_data, y_data\n",
    "\n",
    "def walk_file_tree(relative_path):\n",
    "    X_data = []\n",
    "    y_data = [] \n",
    "    for directory, subdirectories, files in os.walk(relative_path):\n",
    "        for file in files:\n",
    "            if not file.startswith('.'):\n",
    "                path = os.path.join(directory, file)\n",
    "                gesture_name = gestures[file[0:2]]\n",
    "                y_data.append(gestures_map[gesture_name])\n",
    "                X_data.append(process_image(path))   \n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    X_data, y_data = process_data(X_data, y_data)\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path = './frames/silhouettes/'\n",
    "rgb = False\n",
    "\n",
    "# # This method processes the data\n",
    "X_data, y_data = walk_file_tree(relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape: (400, 224, 224, 3)\n",
      "y_data shape: (400, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_data shape: {X_data.shape}')\n",
    "print(f'y_data shape: {y_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b2ade10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = {'image_bw_x': X_data, 'image_bw_y': y_data}\n",
    "df = pd.DataFrame(list(d.items()), columns=['image_bw_x', 'image_bw_y'])\n",
    "df.to_csv('silhouette_df.csv')\n",
    "df = pd.read_csv('silhouette_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  image_bw_x                                         image_bw_y\n",
      "0           0  image_bw_x  [[[[0. 0. 0.]\\n   [0. 0. 0.]\\n   [0. 0. 0.]\\n ...\n",
      "1           1  image_bw_y  [[0. 0. 0. 1.]\\n [0. 0. 0. 1.]\\n [0. 0. 0. 1.]...\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                               min_delta=0,\n",
    "                               patience=10,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state=12, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSize = 224\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "optimizer1 = optimizers.Adam()\n",
    "\n",
    "base_model = vgg_base  # Topless\n",
    "# Add top layer\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu', name='fc1')(x)\n",
    "x = Dense(128, activation='relu', name='fc2')(x)\n",
    "x = Dense(128, activation='relu', name='fc3')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu', name='fc4')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320 samples, validate on 80 samples\n",
      "Epoch 1/5\n",
      "320/320 [==============================] - 89s 278ms/step - loss: 0.1465 - accuracy: 0.9563 - val_loss: 0.2009 - val_accuracy: 0.9500\n",
      "Epoch 2/5\n",
      "320/320 [==============================] - 90s 282ms/step - loss: 0.0704 - accuracy: 0.9719 - val_loss: 0.0896 - val_accuracy: 0.9750\n",
      "Epoch 3/5\n",
      "320/320 [==============================] - 91s 283ms/step - loss: 0.0104 - accuracy: 0.9937 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "320/320 [==============================] - 91s 284ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9750\n",
      "Epoch 5/5\n",
      "320/320 [==============================] - 92s 287ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17dd67910>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './models/saved_model.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(filepath=file_path, save_best_only=True)\n",
    "\n",
    "# Train top layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)]\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:drone] *",
   "language": "python",
   "name": "conda-env-drone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
